{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drbh/speaker_detection\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run program from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No module named ap\n",
      "Warning: failed to import Bob, will use a slower version of MFCC instead.\n",
      "Warning: failed to import fast-gmm, use gmm from scikit-learn instead\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import traceback as tb\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add to run in ipython\n",
    "sys.path.append('./gui/')\n",
    "\n",
    "from interface import ModelInterface\n",
    "from utils import read_wav\n",
    "from filters.silence import remove_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def task_enroll(input_dirs, output_model):\n",
    "    m = ModelInterface()\n",
    "    input_dirs = [os.path.expanduser(k) for k in input_dirs.strip().split()]\n",
    "    dirs = itertools.chain(*(glob.glob(d) for d in input_dirs))\n",
    "    dirs = [d for d in dirs if os.path.isdir(d)]\n",
    "    files = []\n",
    "    print(dirs)\n",
    "    if len(dirs) == 0:\n",
    "        print \"No valid directory found!\"\n",
    "        sys.exit(1)\n",
    "    for d in dirs:\n",
    "        label = os.path.basename(d.rstrip('/'))\n",
    "\n",
    "        wavs = glob.glob(d + '/*.wav')\n",
    "        if len(wavs) == 0:\n",
    "            print \"No wav file found in {0}\".format(d)\n",
    "            continue\n",
    "        print \"Label {0} has files {1}\".format(label, ','.join(wavs))\n",
    "        for wav in wavs:\n",
    "            fs, signal = read_wav(wav)\n",
    "            m.enroll(label, fs, signal)\n",
    "    m.train()\n",
    "#     m.dump(output_model)\n",
    "    \n",
    "    \n",
    "def task_predict(input_files, input_model):\n",
    "    m = ModelInterface.load(input_model)\n",
    "    for f in glob.glob(os.path.expanduser(input_files)):\n",
    "        fs, signal = read_wav(f)\n",
    "        label = m.predict(fs, signal)\n",
    "        print f, '->', label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO\n",
    "\n",
    "    gmmset = gui/gmmset.py\n",
    "    skgmm  = gui/skgmm.py\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./People/David']\n",
      "Label David has files ./People/David/20161228-114451apt.wav,./People/David/20161228-114456apt.wav,./People/David/20161228-114502apt.wav,./People/David/20161228-114507apt.wav,./People/David/20161228-114512apt.wav,./People/David/20161228-114517apt.wav\n",
      "Start training...\n",
      "0.548871040344  seconds\n"
     ]
    }
   ],
   "source": [
    "task_enroll(\"./People/David\",\"model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drbh/Desktop/DV/02_my_name.wav -> DV\n"
     ]
    }
   ],
   "source": [
    "task_predict(\"/Users/drbh/Desktop/DV/02_my_name.wav\",\"model.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "console = True\n",
    "def record_audio(WAVE_OUTPUT_FILENAME):\n",
    "# \tdirec = \"/Users/drbh/speaker_detection/People/David/\"\n",
    "# \tcurtime = time.strftime(\"%Y%m%d-%H%M%S\")  \n",
    "\tCHUNK = 1024\n",
    "\tFORMAT = pyaudio.paInt16\n",
    "\tCHANNELS = 2\n",
    "\tRATE = 44100\n",
    "\tRECORD_SECONDS = 2\n",
    "    \n",
    "# \tWAVE_OUTPUT_FILENAME = direc + curtime + \"apt.wav\"\n",
    "\n",
    "\tWAVE_OUTPUT_FILENAME = WAVE_OUTPUT_FILENAME #\"apt.wav\"\n",
    "\n",
    "\tp = pyaudio.PyAudio()\n",
    "\n",
    "\tstream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "\tif console:\n",
    "\t\tprint \"* Recording audio...\"\n",
    "\n",
    "\tframes = []\n",
    "\n",
    "\tfor i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "\t\tdata = stream.read(CHUNK)\n",
    "\t\tframes.append(data)\n",
    "\n",
    "\tif console:\n",
    "\t\tprint \"* done\\n\" \n",
    "\n",
    "\tstream.stop_stream()\n",
    "\tstream.close()\n",
    "\tp.terminate()\n",
    "\n",
    "\twf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "\twf.setnchannels(CHANNELS)\n",
    "\twf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "\twf.setframerate(RATE)\n",
    "\twf.writeframes(b''.join(frames))\n",
    "\twf.close()\n",
    "    \n",
    "def add_user(name):\n",
    "    record_samples(name,1)\n",
    "    fname = \"/Users/drbh/speaker_detection/People/\" + name + \"/\"\n",
    "    print(fname)\n",
    "    task_enroll(fname,\"model.out\")\n",
    "    \n",
    "    \n",
    "def find_user():\n",
    "    record_audio(\"./tmp.wav\")\n",
    "    task_predict(\"./tmp.wav\",\"model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def record_samples(name, n = 5):\n",
    "    for i in range(1,n):\n",
    "        dirc = \"/Users/drbh/speaker_detection/People/\" + name + \"/\"\n",
    "        fname = time.strftime(\"%Y%m%d-%H%M%S\") \n",
    "        print(i)\n",
    "        record_audio( dirc + fname + \".wav\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "/Users/drbh/speaker_detection/People/Kathy/\n",
      "['/Users/drbh/speaker_detection/People/Kathy/']\n",
      "Label Kathy has files /Users/drbh/speaker_detection/People/Kathy/20161228-114409apt.wav,/Users/drbh/speaker_detection/People/Kathy/20161228-114414apt.wav,/Users/drbh/speaker_detection/People/Kathy/20161228-114419apt.wav,/Users/drbh/speaker_detection/People/Kathy/20161228-114424apt.wav,/Users/drbh/speaker_detection/People/Kathy/20161228-114429apt.wav,/Users/drbh/speaker_detection/People/Kathy/20161228-114435apt.wav\n",
      "Start training...\n",
      "0.319418907166  seconds\n"
     ]
    }
   ],
   "source": [
    "add_user(\"Kathy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_user() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-04b9c96db6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madd_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"David\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: add_user() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kathy 1\n"
     ]
    }
   ],
   "source": [
    "#examine_model \n",
    "tmp_model = ModelInterface.load(\"model.out\")\n",
    "# tmp_model.features.keys()\n",
    "for count, (key, value) in enumerate(tmp_model.features.iteritems(), 1):\n",
    "    print key, count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_model.enroll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Recording audio...\n",
      "* done\n",
      "\n",
      "./tmp.wav -> Kathy\n",
      "* Recording audio...\n",
      "* done\n",
      "\n",
      "./tmp.wav -> Kathy\n",
      "* Recording audio...\n",
      "* done\n",
      "\n",
      "./tmp.wav -> Kathy\n"
     ]
    }
   ],
   "source": [
    "live = True\n",
    "while live is True:\n",
    "    for i in range(1,4):\n",
    "        find_user()\n",
    "    live = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Recording audio...\n",
      "* done\n",
      "\n",
      "apt.wav -> David\n"
     ]
    }
   ],
   "source": [
    "find_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apt.wav -> David\n"
     ]
    }
   ],
   "source": [
    "task_predict(\"apt.wav\",\"model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./People/Kathy/20161228-114429apt.wav -> David\n"
     ]
    }
   ],
   "source": [
    "task_predict(\"./People/Kathy/20161228-114429apt.wav\",\"model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONV_INTERVAL = 0.4\n",
    "CONV_DURATION = 1.5\n",
    "CONV_FILTER_DURATION = CONV_DURATION\n",
    "FS = 8000\n",
    "TEST_DURATION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
