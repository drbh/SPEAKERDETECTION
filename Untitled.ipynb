{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Kathy 2775\n",
      "2 Luke 2775\n",
      "3 David 3515\n",
      "4 Nick 2590\n",
      "5 Joe 2405\n",
      "6 Lauren 2405\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import traceback as tb\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add to run in ipython\n",
    "sys.path.append('./gui/')\n",
    "\n",
    "from interface import ModelInterface\n",
    "from utils import read_wav\n",
    "from filters.silence import remove_silence\n",
    "from feature import mix_feature\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "\n",
    "console = False\n",
    "def record_audio(WAVE_OUTPUT_FILENAME):\n",
    "# \tdirec = \"/Users/drbh/speaker_detection/People/David/\"\n",
    "# \tcurtime = time.strftime(\"%Y%m%d-%H%M%S\")  \n",
    "\t# CHUNK = 1024\n",
    "\tCHUNK = 600\n",
    "\tFORMAT = pyaudio.paInt16#paInt32 #\n",
    "\tCHANNELS = 2\n",
    "\tRATE = 44100\n",
    "\t# RECORD_SECONDS = 3\n",
    "\tRECORD_SECONDS = 3\n",
    "    \n",
    "# \tWAVE_OUTPUT_FILENAME = direc + curtime + \"apt.wav\"\n",
    "\n",
    "\tWAVE_OUTPUT_FILENAME = WAVE_OUTPUT_FILENAME #\"apt.wav\"\n",
    "\n",
    "\tp = pyaudio.PyAudio()\n",
    "\n",
    "\tstream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "\tif console:\n",
    "\t\tprint \"* Recording audio...\"\n",
    "\n",
    "\tframes = []\n",
    "\n",
    "\tfor i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "\t\tdata = stream.read(CHUNK)\n",
    "\t\tframes.append(data)\n",
    "\n",
    "\tif console:\n",
    "\t\tprint \"* done\\n\" \n",
    "\n",
    "\tstream.stop_stream()\n",
    "\tstream.close()\n",
    "\tp.terminate()\n",
    "\n",
    "\twf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "\twf.setnchannels(CHANNELS)\n",
    "\twf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "\twf.setframerate(RATE)\n",
    "\twf.writeframes(b''.join(frames))\n",
    "\twf.close()\n",
    "\n",
    "\n",
    "def record_samples(name, n = 20):\n",
    "    for i in range(1,n):\n",
    "        dirc = \"./People/\" + name + \"/\"\n",
    "        fname = time.strftime(\"%Y%m%d-%H%M%S\") \n",
    "        print(i)\n",
    "        record_audio( dirc + fname + \".wav\")\n",
    "    print(\"done\")\n",
    "    \n",
    "def see_model(mods):\n",
    "    for count, (key, value) in enumerate(mods.features.iteritems(), 1):\n",
    "        print count, key, len(value)\n",
    "        \n",
    "def add_user_to_model(model,name):\n",
    "    m = model\n",
    "    fname = \"./People/\" + name + \"/\"\n",
    "    input_dirs = fname\n",
    "    input_dirs = [os.path.expanduser(k) for k in input_dirs.strip().split()]\n",
    "    dirs = itertools.chain(*(glob.glob(d) for d in input_dirs))\n",
    "    dirs = [d for d in dirs if os.path.isdir(d)]\n",
    "    files = []\n",
    "    print(dirs)\n",
    "    if len(dirs) == 0:\n",
    "        print \"No valid directory found!\"\n",
    "        sys.exit(1)\n",
    "    for d in dirs:\n",
    "        label = os.path.basename(d.rstrip('/'))\n",
    "\n",
    "        wavs = glob.glob(d + '/*.wav')\n",
    "        if len(wavs) == 0:\n",
    "            print \"No wav file found in {0}\".format(d)\n",
    "            continue\n",
    "        print \"Label {0} has files {1}\".format(label, ','.join(wavs))\n",
    "        for wav in wavs:\n",
    "            fs, signal = read_wav(wav)\n",
    "#             fs, signal = check_vad(fs, signal)\n",
    "            if len(signal) > 0:\n",
    "                m.enroll(label, fs, signal)\n",
    "    m.train()\n",
    "    \n",
    "def record_samples(name, n = 20):\n",
    "    for i in range(1,n):\n",
    "        dirc = \"./People/\" + name + \"/\"\n",
    "        fname = time.strftime(\"%Y%m%d-%H%M%S\") \n",
    "        print(i)\n",
    "        record_audio( dirc + fname + \".wav\")\n",
    "    print(\"done\")\n",
    "\n",
    "def test_model(mods,path = \"./tmp.wav\"):\n",
    "    fs, signal = read_wav(path)\n",
    "    feat = mix_feature((fs, signal))\n",
    "    x = feat\n",
    "    scores = [mods.gmmset.gmm_score(gmm, x) / len(x) for gmm in mods.gmmset.gmms]\n",
    "    import operator\n",
    "    p = sorted(enumerate(scores), key=operator.itemgetter(1), reverse=True)\n",
    "    p = [(str(mods.gmmset.y[i]), y, p[0][1] - y) for i, y in p]\n",
    "    result = [(mods.gmmset.y[index], value) for (index, value) in enumerate(scores)]\n",
    "    p = max(result, key=operator.itemgetter(1))\n",
    "    return result\n",
    "    \n",
    "def find_user():\n",
    "    #print(\" + Recording\")\n",
    "    record_audio(\"./tmp.wav\")\n",
    "    #print(\" + Predicting\")\n",
    "    input_model = \"model.out\"\n",
    "    input_files = \"./tmp.wav\"\n",
    "    m = ModelInterface.load(input_model)\n",
    "#     m = model\n",
    "    for f in glob.glob(os.path.expanduser(input_files)):\n",
    "        fs, signal = read_wav(f)\n",
    "        label = m.predict(fs, signal)\n",
    "#         print max(label, key=operator.itemgetter(1))\n",
    "        if abs(label[0][1] - label[1][1]) > .0000002:\n",
    "            speakers_detected = [x for x in label if x[1] >= -.1]\n",
    "            if len(speakers_detected) > 0:\n",
    "                print max(speakers_detected, key=operator.itemgetter(1))\n",
    "            else:\n",
    "                print \"___              not similar enough to know speaker\",\"       Best guess:\", max(label, key=operator.itemgetter(1))\n",
    "        else:\n",
    "            print \"...                          predictions too similar\",\"       Best guess:\", max(label, key=operator.itemgetter(1))\n",
    "\n",
    "mods = ModelInterface()\n",
    "\n",
    "mods = mods.load(\"./model.out\")\n",
    "see_model(mods)\n",
    "\n",
    "import operator\n",
    "\n",
    "# find_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNK = 600\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 3\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "            channels=CHANNELS,\n",
    "            rate=RATE,\n",
    "            input=True,\n",
    "            frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___              not similar enough to know speaker        Best guess: ('David', -0.38388307072253486)\n"
     ]
    }
   ],
   "source": [
    "find_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pyaudio\r\n",
      "import wave\r\n",
      "\r\n",
      "\r\n",
      "console = False\r\n",
      "def record_audio(WAVE_OUTPUT_FILENAME):\r\n",
      "# \tdirec = \"/Users/drbh/speaker_detection/People/David/\"\r\n",
      "# \tcurtime = time.strftime(\"%Y%m%d-%H%M%S\")  \r\n",
      "\t# CHUNK = 1024\r\n",
      "\tCHUNK = 600\r\n",
      "\tFORMAT = pyaudio.paInt16#paInt32 #\r\n",
      "\tCHANNELS = 2\r\n",
      "\tRATE = 44100\r\n",
      "\t# RECORD_SECONDS = 3\r\n",
      "\tRECORD_SECONDS = 3\r\n",
      "    \r\n",
      "# \tWAVE_OUTPUT_FILENAME = direc + curtime + \"apt.wav\"\r\n",
      "\r\n",
      "\tWAVE_OUTPUT_FILENAME = WAVE_OUTPUT_FILENAME #\"apt.wav\"\r\n",
      "\r\n",
      "\tp = pyaudio.PyAudio()\r\n",
      "\r\n",
      "\tstream = p.open(format=FORMAT,\r\n",
      "                channels=CHANNELS,\r\n",
      "                rate=RATE,\r\n",
      "                input=True,\r\n",
      "                frames_per_buffer=CHUNK)\r\n",
      "\r\n",
      "\tif console:\r\n",
      "\t\tprint \"* Recording audio...\"\r\n",
      "\r\n",
      "\tframes = []\r\n",
      "\r\n",
      "\tfor i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\r\n",
      "\t\tdata = stream.read(CHUNK)\r\n",
      "\t\tframes.append(data)\r\n",
      "\r\n",
      "\tif console:\r\n",
      "\t\tprint \"* done\\n\" \r\n",
      "\r\n",
      "\tstream.stop_stream()\r\n",
      "\tstream.close()\r\n",
      "\tp.terminate()\r\n",
      "\r\n",
      "\twf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\r\n",
      "\twf.setnchannels(CHANNELS)\r\n",
      "\twf.setsampwidth(p.get_sample_size(FORMAT))\r\n",
      "\twf.setframerate(RATE)\r\n",
      "\twf.writeframes(b''.join(frames))\r\n",
      "\twf.close()\r\n"
     ]
    }
   ],
   "source": [
    "!cat audios.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
